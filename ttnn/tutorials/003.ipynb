{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Multi-Head Attention\n",
                "\n",
                "Multi-Head Attention is an important part of all Transformer-based models.\n",
                "This tutorial will show how to write it and how to then optimize it."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[38;2;000;128;000m                  Metal\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Initializing device 0\n",
                        "\u001b[38;2;000;128;000m                 Device\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Opening user mode device driver\n",
                        "\u001b[32m2024-01-29 23:03:02.348\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Detected 1 PCI device : {0}\n",
                        "\u001b[32m2024-01-29 23:03:02.359\u001b[0m | \u001b[1m\u001b[38;2;255;165;000mWARNING \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - init_detect_tt_device_numanodes(): Could not determine NumaNodeSet for TT device (physical_device_id: 0 pci_bus_id: 0000:00:08.0)\n",
                        "\u001b[32m2024-01-29 23:03:02.359\u001b[0m | \u001b[1m\u001b[38;2;255;165;000mWARNING \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - Could not find NumaNodeSet for TT Device (physical_device_id: 0 pci_bus_id: 0000:00:08.0)\n",
                        "\u001b[32m2024-01-29 23:03:02.360\u001b[0m | \u001b[1m\u001b[38;2;255;165;000mWARNING \u001b[0m | \u001b[36mSiliconDriver  \u001b[0m - bind_area_memory_nodeset(): Unable to determine TT Device to NumaNode mapping for physical_device_id: 0. Skipping membind.\n",
                        "\u001b[0;33m---- ttSiliconDevice::init_hugepage: bind_area_to_memory_nodeset() failed (physical_device_id: 0 ch: 0). Hugepage allocation is not on NumaNode matching TT Device. Side-Effect is decreased Device->Host perf (Issue #893).\n",
                        "\u001b[0m\u001b[38;2;000;128;000m                  Metal\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | AI CLK for device 0 is:   1202 MHz\n"
                    ]
                }
            ],
            "source": [
                "import time\n",
                "import torch\n",
                "import ttnn\n",
                "\n",
                "torch.manual_seed(0)\n",
                "\n",
                "device_id = 0\n",
                "device = ttnn.open_device(device_id=device_id)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Enable program cache"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Program Cache: enabled.\n"
                    ]
                }
            ],
            "source": [
                "ttnn.enable_program_cache(device)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Write Multi-Head Attention using ttnn\n",
                "\n",
                "Multi-head can be implemented in `torch` using just 6 operations:\n",
                "\n",
                "1. `torch.matmul`\n",
                "2. `torch.add`\n",
                "3. `torch.reshape`\n",
                "4. `torch.permute`\n",
                "5. `torch.mul`\n",
                "6. `torch.softmax`\n",
                "\n",
                "`ttnn` provides the exact same APIs to do that and therefore multi-head attention can be implemented in a very similar fashion. Except, when using `ttnn`, the user should be mindful of the tensor layout."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "def multi_head_attention(\n",
                "    hidden_states,\n",
                "    query_weight,\n",
                "    query_bias,\n",
                "    key_weight,\n",
                "    key_bias,\n",
                "    value_weight,\n",
                "    value_bias,\n",
                "    output_weight,\n",
                "    output_bias,\n",
                "    *,\n",
                "    num_heads,\n",
                "):\n",
                "    batch_size, sequence_size, hidden_size = hidden_states.shape\n",
                "    head_size = hidden_size // num_heads\n",
                "\n",
                "    query = hidden_states @ query_weight\n",
                "    query = query + query_bias\n",
                "    query = ttnn.to_layout(query, layout=ttnn.ROW_MAJOR_LAYOUT)\n",
                "    query = ttnn.reshape(query, (batch_size, sequence_size, num_heads, head_size))\n",
                "    query = ttnn.to_layout(query, layout=ttnn.TILE_LAYOUT)\n",
                "    query = ttnn.permute(query, (0, 2, 1, 3))\n",
                "\n",
                "    key = hidden_states @ key_weight\n",
                "    key = key + key_bias\n",
                "    key = ttnn.to_layout(key, layout=ttnn.ROW_MAJOR_LAYOUT)\n",
                "    key = ttnn.reshape(key, (batch_size, sequence_size, num_heads, head_size))\n",
                "    key = ttnn.to_layout(key, layout=ttnn.TILE_LAYOUT)\n",
                "    key = ttnn.permute(key, (0, 2, 3, 1))\n",
                "\n",
                "    value = hidden_states @ value_weight\n",
                "    value = value + value_bias\n",
                "    value = ttnn.to_layout(value, layout=ttnn.ROW_MAJOR_LAYOUT)\n",
                "    value = ttnn.reshape(value, (batch_size, sequence_size, num_heads, head_size))\n",
                "    value = ttnn.to_layout(value, layout=ttnn.TILE_LAYOUT)\n",
                "    value = ttnn.permute(value, (0, 2, 1, 3))\n",
                "\n",
                "    attention_scores = query @ key\n",
                "    attention_scores = attention_scores * (1 / (head_size**0.5))\n",
                "    attention_probs = ttnn.softmax(attention_scores, dim=-1)\n",
                "\n",
                "    context_layer = attention_probs @ value\n",
                "    context_layer = ttnn.permute(context_layer, (0, 2, 1, 3))\n",
                "    context_layer = ttnn.to_layout(context_layer, layout=ttnn.ROW_MAJOR_LAYOUT)\n",
                "    context_layer = ttnn.reshape(context_layer, (batch_size, sequence_size, hidden_size))\n",
                "    context_layer = ttnn.to_layout(context_layer, layout=ttnn.TILE_LAYOUT)\n",
                "\n",
                "    self_output = context_layer @ output_weight\n",
                "    self_output = self_output + output_bias\n",
                "\n",
                "    return self_output"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now that the model is written, let's create input tensors to run it and test it"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "batch_size = 8\n",
                "sequence_size = 384\n",
                "num_heads = 16\n",
                "head_size = 64\n",
                "hidden_size = num_heads * head_size"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Initialize activations and weights using torch"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "torch_hidden_states = torch.randn((batch_size, sequence_size, hidden_size), dtype=torch.bfloat16)\n",
                "torch_query_weight = torch.randn((hidden_size, hidden_size), dtype=torch.bfloat16)\n",
                "torch_query_bias = torch.randn((hidden_size,), dtype=torch.bfloat16)\n",
                "torch_key_weight = torch.randn((hidden_size, hidden_size), dtype=torch.bfloat16)\n",
                "torch_key_bias = torch.randn((hidden_size,), dtype=torch.bfloat16)\n",
                "torch_value_weight = torch.randn((hidden_size, hidden_size), dtype=torch.bfloat16)\n",
                "torch_value_bias = torch.randn((hidden_size,), dtype=torch.bfloat16)\n",
                "torch_output_weight = torch.randn((hidden_size, hidden_size), dtype=torch.bfloat16)\n",
                "torch_output_bias = torch.randn((hidden_size,), dtype=torch.bfloat16)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Convert activations and weights to ttnn"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.from_torch                                    in          176269 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_device                                     in          632226 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.from_torch                                    in           70980 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_device                                     in          231089 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.from_torch                                    in           40020 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           32210 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_layout                                     in          660057 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           23350 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_device                                     in           44300 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.from_torch                                    in           34340 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_device                                     in          476758 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.from_torch                                    in           39879 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           28260 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_layout                                     in          595386 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           21590 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_device                                     in           44159 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.from_torch                                    in           36219 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_device                                     in          155729 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.from_torch                                    in           33550 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           24550 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_layout                                     in          628436 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           22830 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_device                                     in           41569 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.from_torch                                    in           32980 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_device                                     in          159519 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.from_torch                                    in           39660 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           24790 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_layout                                     in          593406 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           64140 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_device                                     in           41609 nanoseconds\n"
                    ]
                }
            ],
            "source": [
                "hidden_states = ttnn.from_torch(torch_hidden_states, layout=ttnn.TILE_LAYOUT, device=device)\n",
                "query_weight = ttnn.from_torch(torch_query_weight, layout=ttnn.TILE_LAYOUT, device=device)\n",
                "query_bias = ttnn.from_torch(torch_query_bias, layout=ttnn.TILE_LAYOUT, device=device, memory_config=ttnn.L1_MEMORY_CONFIG)\n",
                "key_weight = ttnn.from_torch(torch_key_weight, layout=ttnn.TILE_LAYOUT, device=device)\n",
                "key_bias = ttnn.from_torch(torch_key_bias, layout=ttnn.TILE_LAYOUT, device=device, memory_config=ttnn.L1_MEMORY_CONFIG)\n",
                "value_weight = ttnn.from_torch(torch_value_weight, layout=ttnn.TILE_LAYOUT, device=device)\n",
                "value_bias = ttnn.from_torch(torch_value_bias, layout=ttnn.TILE_LAYOUT, device=device, memory_config=ttnn.L1_MEMORY_CONFIG)\n",
                "output_weight = ttnn.from_torch(torch_output_weight, layout=ttnn.TILE_LAYOUT, device=device)\n",
                "output_bias = ttnn.from_torch(torch_output_bias, layout=ttnn.TILE_LAYOUT, device=device, memory_config=ttnn.L1_MEMORY_CONFIG)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Run the first iteration of Multi-Head Attention"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           32270 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           21740 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Matmul                               in       575025407 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Matmul                               in       575270035 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in          104509 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           35180 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           21010 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::EltwiseBinaryBroadcast               in       523957785 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::EltwiseBinaryBroadcast               in       524278024 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in          106079 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Untilize                             in       482910126 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Untilize                             in       483007896 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.from_device                                   in         6055056 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_torch                                      in         1280023 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation torch.reshape                                      in        15716041 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.from_torch                                    in           86869 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_device                                     in         1104654 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           30620 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::TilizeWithValPadding                 in       661298950 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::TilizeWithValPadding                 in       661399249 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::UntilizeWithUnpadding                in       468061090 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::UntilizeWithUnpadding                in       468197989 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::TilizeWithValPadding                 in       148156584 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::TilizeWithValPadding                 in       148222594 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Transpose                            in       537434858 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Transpose                            in       537737117 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Unpad                                in       424969173 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Unpad                                in       425244511 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           79920 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           21420 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Matmul                               in         1164084 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Matmul                               in         1195883 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           25770 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           50100 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           23050 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::EltwiseBinaryBroadcast               in          600996 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::EltwiseBinaryBroadcast               in          688806 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           27170 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Untilize                             in         5807257 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Untilize                             in         5827447 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.from_device                                   in         5500909 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_torch                                      in          273199 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation torch.reshape                                      in         1773970 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.from_torch                                    in           64409 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_device                                     in         1318133 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           25990 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::TilizeWithValPadding                 in       162866181 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::TilizeWithValPadding                 in       162896731 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::UntilizeWithUnpadding                in        13936651 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::UntilizeWithUnpadding                in        13962981 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::TilizeWithValPadding                 in       148118975 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::TilizeWithValPadding                 in       148145715 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Transpose                            in         6001066 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Transpose                            in         6053166 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Transpose                            in       462894099 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Transpose                            in       463182518 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Unpad                                in          365198 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Unpad                                in          462647 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           91779 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           23750 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Matmul                               in         1137654 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Matmul                               in         1171894 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           26030 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           21630 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           19650 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::EltwiseBinaryBroadcast               in          601027 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::EltwiseBinaryBroadcast               in          687317 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           25680 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Untilize                             in         5802107 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Untilize                             in         5824247 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.from_device                                   in         6343755 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_torch                                      in          450187 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation torch.reshape                                      in         1103164 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.from_torch                                    in           64490 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_device                                     in         1115584 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           27430 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::TilizeWithValPadding                 in       162819512 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::TilizeWithValPadding                 in       162855411 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::UntilizeWithUnpadding                in        13942241 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::UntilizeWithUnpadding                in        13974521 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::TilizeWithValPadding                 in       148111065 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::TilizeWithValPadding                 in       148145165 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Transpose                            in         6044486 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Transpose                            in         6132735 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Unpad                                in          360408 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Unpad                                in          438848 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Matmul                               in       545248315 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Matmul                               in       545529283 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::DataTransferToDevice                 in           43019 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::EltwiseBinaryBroadcast               in       478931539 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::EltwiseBinaryBroadcast               in       479241557 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::operations::primary::Softmax                   in       839522315 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::operations::primary::Softmax                   in       839831613 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Matmul                               in       466278290 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Matmul                               in       466586888 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Pad                                  in       449430344 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Pad                                  in       449517724 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Transpose                            in         8440692 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Transpose                            in         8531992 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::UntilizeWithUnpadding                in        14276879 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::UntilizeWithUnpadding                in        14333979 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::TilizeWithValPadding                 in       148025935 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::TilizeWithValPadding                 in       148068795 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::UntilizeWithUnpadding                in        13942391 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::UntilizeWithUnpadding                in        13966391 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.from_device                                   in        19219052 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_torch                                      in          233659 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation torch.reshape                                      in         4287806 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.from_torch                                    in           64660 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_device                                     in         3489760 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           35580 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Tilize                               in       497208655 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Tilize                               in       497296224 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in          102110 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           21860 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Matmul                               in         1158324 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Matmul                               in         1197873 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           24680 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           24620 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           22619 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::EltwiseBinaryBroadcast               in          597966 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::EltwiseBinaryBroadcast               in          691006 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           22560 nanoseconds\n"
                    ]
                }
            ],
            "source": [
                "start = time.time()\n",
                "multi_head_attention(\n",
                "    hidden_states,\n",
                "    query_weight,\n",
                "    query_bias,\n",
                "    key_weight,\n",
                "    key_bias,\n",
                "    value_weight,\n",
                "    value_bias,\n",
                "    output_weight,\n",
                "    output_bias,\n",
                "    num_heads=num_heads,\n",
                ")\n",
                "end = time.time()\n",
                "duration = end - start"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Multi-head attention ran in 8.523182153701782 seconds for the first iteration\n"
                    ]
                }
            ],
            "source": [
                "print(f\"Multi-head attention ran in {duration} seconds for the first iteration\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Run a subsequent iteration of Multi-Head Attention"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           34220 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           22370 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Matmul                               in         1132823 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Matmul                               in         1150703 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           21670 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           19700 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           19690 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::EltwiseBinaryBroadcast               in          590297 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::EltwiseBinaryBroadcast               in          627257 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           22750 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Untilize                             in         5802787 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Untilize                             in         5822087 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.from_device                                   in         5499859 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_torch                                      in          431498 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation torch.reshape                                      in         8228783 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.from_torch                                    in           62639 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_device                                     in         1119244 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           24939 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::TilizeWithValPadding                 in       162851621 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::TilizeWithValPadding                 in       162882811 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::UntilizeWithUnpadding                in        13940162 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::UntilizeWithUnpadding                in        13968632 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::TilizeWithValPadding                 in       148099034 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::TilizeWithValPadding                 in       148120764 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Transpose                            in         6001546 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Transpose                            in         6087556 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Unpad                                in          364038 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Unpad                                in          448017 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           42950 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           19440 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Matmul                               in         1125704 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Matmul                               in         1146614 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           22710 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           18709 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           18960 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::EltwiseBinaryBroadcast               in          593117 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::EltwiseBinaryBroadcast               in          630166 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           21630 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Untilize                             in         5801948 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Untilize                             in         5818098 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.from_device                                   in         4244516 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_torch                                      in           92799 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation torch.reshape                                      in         4679543 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.from_torch                                    in           71810 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_device                                     in         4168967 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           47310 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::TilizeWithValPadding                 in       162749823 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::TilizeWithValPadding                 in       162781182 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::UntilizeWithUnpadding                in        13940512 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::UntilizeWithUnpadding                in        13964361 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::TilizeWithValPadding                 in       148180534 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::TilizeWithValPadding                 in       148204694 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Transpose                            in         5975936 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Transpose                            in         6049035 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Transpose                            in          644726 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Transpose                            in          725136 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Unpad                                in          355188 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Unpad                                in          428478 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           40440 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           19119 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Matmul                               in         1115254 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Matmul                               in         1139414 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           27320 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           19570 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           19550 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::EltwiseBinaryBroadcast               in          593537 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::EltwiseBinaryBroadcast               in          633967 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           22120 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Untilize                             in         5801698 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Untilize                             in         5815778 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.from_device                                   in         7217610 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_torch                                      in           93530 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation torch.reshape                                      in          924785 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.from_torch                                    in           53690 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_device                                     in         1141793 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           23180 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::TilizeWithValPadding                 in       162912251 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::TilizeWithValPadding                 in       162937171 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::UntilizeWithUnpadding                in        13925112 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::UntilizeWithUnpadding                in        13945151 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::TilizeWithValPadding                 in       148056185 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::TilizeWithValPadding                 in       148078645 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Transpose                            in         5988266 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Transpose                            in         6044816 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Unpad                                in          348808 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Unpad                                in          406758 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Matmul                               in         3476791 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Matmul                               in         3513211 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::DataTransferToDevice                 in           19020 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::EltwiseBinaryBroadcast               in         1837859 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::EltwiseBinaryBroadcast               in         1911639 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::operations::primary::Softmax                   in         1673600 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::operations::primary::Softmax                   in         1760440 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Matmul                               in         2472866 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Matmul                               in         2502806 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Pad                                  in         5377870 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Pad                                  in         5395810 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Transpose                            in         8550212 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Transpose                            in         8587622 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::UntilizeWithUnpadding                in        13924671 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::UntilizeWithUnpadding                in        13947431 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::TilizeWithValPadding                 in       148141094 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::TilizeWithValPadding                 in       148164644 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::UntilizeWithUnpadding                in        13922972 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::UntilizeWithUnpadding                in        13941372 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.from_device                                   in        20743373 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_torch                                      in          131469 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation torch.reshape                                      in         2156518 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.from_torch                                    in           60379 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_device                                     in         2477166 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           24540 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Tilize                               in         6673373 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Tilize                               in         6692493 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           24960 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           19420 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::Matmul                               in         1108864 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::Matmul                               in         1126274 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           21060 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           18599 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           18110 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::EltwiseBinaryBroadcast               in          569687 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::EltwiseBinaryBroadcast               in          612926 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           21660 nanoseconds\n"
                    ]
                }
            ],
            "source": [
                "start = time.time()\n",
                "output = multi_head_attention(\n",
                "    hidden_states,\n",
                "    query_weight,\n",
                "    query_bias,\n",
                "    key_weight,\n",
                "    key_bias,\n",
                "    value_weight,\n",
                "    value_bias,\n",
                "    output_weight,\n",
                "    output_bias,\n",
                "    num_heads=num_heads,\n",
                ")\n",
                "end = time.time()\n",
                "duration = end - start"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Multi-head attention ran in 1.3022534847259521 seconds for the subsequent iteration because of the program cache\n"
                    ]
                }
            ],
            "source": [
                "print(f\"Multi-head attention ran in {duration} seconds for the subsequent iteration because of the program cache\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Write optimized version of Multi-Head Attention\n",
                "\n",
                "Optimized version of the multi-head attention can be written by:\n",
                "\n",
                "- Tilizing all of the tensors ahead of time\n",
                "- Using more performant matmuls that fuse bias and specify the number of cores they execute on\n",
                "- Putting every tensor into L1\n",
                "- Using bfloat8_b data_type\n",
                "- Using custom `ttnn.transformer` operations instead of `ttnn.permute` and `ttnn.reshape`\n",
                "\n",
                "`ttnn.deallocate` calls are needed because otherwise, the cores on the device will run out of the L1 memory"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "def optimized_multi_head_attention(\n",
                "    hidden_states,\n",
                "    fused_qkv_weight,\n",
                "    fused_qkv_bias,\n",
                "    self_output_weight,\n",
                "    self_output_bias,\n",
                "    *,\n",
                "    num_heads,\n",
                "    num_cores_x=12,\n",
                "):\n",
                "    batch_size, _, hidden_size = hidden_states.shape\n",
                "    head_size = hidden_size // num_heads\n",
                "    \n",
                "    hidden_states = ttnn.to_layout(hidden_states, ttnn.TILE_LAYOUT)\n",
                "\n",
                "    fused_qkv_output = ttnn.linear(\n",
                "        hidden_states,\n",
                "        fused_qkv_weight,\n",
                "        bias=fused_qkv_bias,\n",
                "        memory_config=ttnn.L1_MEMORY_CONFIG,\n",
                "        dtype=ttnn.bfloat8_b,\n",
                "        core_grid=ttnn.CoreGrid(y=batch_size, x=num_cores_x),\n",
                "    )\n",
                "\n",
                "    (\n",
                "        query,\n",
                "        key,\n",
                "        value,\n",
                "    ) = ttnn.transformer.split_query_key_value_and_split_heads(\n",
                "        fused_qkv_output,\n",
                "        memory_config=ttnn.L1_MEMORY_CONFIG,\n",
                "        num_heads=num_heads,\n",
                "    )\n",
                "    ttnn.deallocate(fused_qkv_output)\n",
                "\n",
                "    attention_scores = ttnn.matmul(\n",
                "        query,\n",
                "        key,\n",
                "        memory_config=ttnn.L1_MEMORY_CONFIG,\n",
                "        dtype=ttnn.bfloat16,\n",
                "        core_grid=ttnn.CoreGrid(y=batch_size, x=num_cores_x),\n",
                "    )\n",
                "    ttnn.deallocate(query)\n",
                "    ttnn.deallocate(key)\n",
                "\n",
                "    attention_probs = ttnn.transformer.attention_softmax(attention_scores, attention_mask=None, head_size=head_size)\n",
                "\n",
                "    context_layer = ttnn.matmul(\n",
                "        attention_probs,\n",
                "        value,\n",
                "        memory_config=ttnn.L1_MEMORY_CONFIG,\n",
                "        dtype=ttnn.bfloat8_b,\n",
                "        core_grid=ttnn.CoreGrid(y=batch_size, x=num_cores_x),\n",
                "    )\n",
                "    ttnn.deallocate(attention_probs)\n",
                "\n",
                "    context_layer = ttnn.transformer.concatenate_heads(\n",
                "        context_layer,\n",
                "        memory_config=ttnn.L1_MEMORY_CONFIG,\n",
                "    )\n",
                "\n",
                "    self_output = ttnn.linear(\n",
                "        context_layer,\n",
                "        self_output_weight,\n",
                "        bias=self_output_bias,\n",
                "        memory_config=ttnn.L1_MEMORY_CONFIG,\n",
                "        dtype=ttnn.bfloat16,\n",
                "        core_grid=ttnn.CoreGrid(y=batch_size, x=num_cores_x),\n",
                "    )\n",
                "    ttnn.deallocate(context_layer)\n",
                "\n",
                "    return self_output"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Pre-process the parameters of the optimized model\n",
                "\n",
                "1. Fuse QKV weights and biases\n",
                "2. Reshape and tilize for the optimized operations using preprocess_linear_weight and preprocess_linear_bias\n",
                "3. Move to device"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.from_torch                                    in           52410 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.from_torch                                    in           66640 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           31090 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_layout                                     in         1762091 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           21590 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.from_torch                                    in           36309 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.from_torch                                    in           44360 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           24650 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_layout                                     in          587366 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           21420 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_device                                     in         3900648 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_device                                     in          174279 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_device                                     in         1460102 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_device                                     in           51439 nanoseconds\n"
                    ]
                }
            ],
            "source": [
                "from ttnn.model_preprocessing import (\n",
                "    preprocess_linear_bias,\n",
                "    preprocess_linear_weight,\n",
                ")\n",
                "\n",
                "torch_qkv_weight = torch.cat([torch_query_weight, torch_key_weight, torch_value_weight], dim=-1)\n",
                "torch_qkv_bias = torch.cat([torch_query_bias, torch_key_bias, torch_value_bias], dim=-1)\n",
                "\n",
                "qkv_weight = preprocess_linear_weight(torch_qkv_weight.T, dtype=ttnn.bfloat16)\n",
                "qkv_bias = preprocess_linear_bias(torch_qkv_bias, dtype=ttnn.bfloat16)\n",
                "output_weight = preprocess_linear_weight(torch_output_weight.T, dtype=ttnn.bfloat16)\n",
                "output_bias = preprocess_linear_bias(torch_output_bias, dtype=ttnn.bfloat16)\n",
                "\n",
                "qkv_weight = ttnn.to_device(qkv_weight, device)\n",
                "qkv_bias = ttnn.to_device(qkv_bias, device, memory_config=ttnn.L1_MEMORY_CONFIG)\n",
                "output_weight = ttnn.to_device(output_weight, device)\n",
                "output_bias = ttnn.to_device(output_bias, device, memory_config=ttnn.L1_MEMORY_CONFIG)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Run the first iteration of the optimized Multi-Head Attention"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           29390 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           21450 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           19660 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::operations::primary::Matmul                    in       705351421 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::operations::primary::Matmul                    in       705757609 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           86489 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           22370 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::operations::primary::transformers::SplitFusedQKVAndSplitHeads in       500565536 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::operations::primary::transformers::SplitFusedQKVAndSplitHeads in       500856325 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.deallocate                                    in           37240 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::operations::primary::Matmul                    in       638500319 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::operations::primary::Matmul                    in       638799567 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.deallocate                                    in           42480 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.deallocate                                    in           11070 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::DataTransferToDevice                 in           37750 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::EltwiseBinaryBroadcast               in       435971591 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::EltwiseBinaryBroadcast               in       436267259 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::operations::primary::Softmax                   in         1680900 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::operations::primary::Softmax                   in         1782950 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::operations::primary::Matmul                    in       641136744 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::operations::primary::Matmul                    in       641450752 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.deallocate                                    in           53530 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::NlpConcatHeads                       in       453542711 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::NlpConcatHeads                       in       453814259 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           70740 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           22930 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           19720 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           17999 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::operations::primary::Matmul                    in       697704044 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::operations::primary::Matmul                    in       698126972 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in          104729 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.deallocate                                    in           19890 nanoseconds\n"
                    ]
                }
            ],
            "source": [
                "start = time.time()\n",
                "hidden_states = ttnn.to_layout(hidden_states, ttnn.TILE_LAYOUT)\n",
                "optimized_output = optimized_multi_head_attention(\n",
                "    hidden_states,\n",
                "    qkv_weight,\n",
                "    qkv_bias,\n",
                "    output_weight,\n",
                "    output_bias,\n",
                "    num_heads=num_heads,\n",
                ")\n",
                "end = time.time()\n",
                "duration = end - start"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Optimized multi-head attention ran in 4.085210084915161 seconds for the first iteration\n"
                    ]
                }
            ],
            "source": [
                "print(f\"Optimized multi-head attention ran in {duration} seconds for the first iteration\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Run a subsequent iteration of the optimized Multi-Head Attention"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           36490 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           25260 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           20770 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::operations::primary::Matmul                    in          372968 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::operations::primary::Matmul                    in          443737 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           26250 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           24000 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::operations::primary::transformers::SplitFusedQKVAndSplitHeads in          104309 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::operations::primary::transformers::SplitFusedQKVAndSplitHeads in          146429 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.deallocate                                    in           11110 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::operations::primary::Matmul                    in          233868 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::operations::primary::Matmul                    in          270358 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.deallocate                                    in           10400 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.deallocate                                    in            7640 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::DataTransferToDevice                 in           27670 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::EltwiseBinaryBroadcast               in         1303123 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::EltwiseBinaryBroadcast               in         1376642 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::operations::primary::Softmax                   in         1672111 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::operations::primary::Softmax                   in         1762250 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::operations::primary::Matmul                    in          633157 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::operations::primary::Matmul                    in          685736 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.deallocate                                    in           14759 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::tt_metal::NlpConcatHeads                       in           80080 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::tt_metal::NlpConcatHeads                       in          108710 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           27980 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           23510 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           19080 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           18320 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Program   tt::operations::primary::Matmul                    in          232119 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation tt::operations::primary::Matmul                    in          252829 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.reshape                                       in           23520 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.deallocate                                    in            9100 nanoseconds\n"
                    ]
                }
            ],
            "source": [
                "start = time.time()\n",
                "optimized_output = optimized_multi_head_attention(\n",
                "    hidden_states,\n",
                "    qkv_weight,\n",
                "    qkv_bias,\n",
                "    output_weight,\n",
                "    output_bias,\n",
                "    num_heads=num_heads,\n",
                ")\n",
                "end = time.time()\n",
                "duration = end - start"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Optimized multi-head attention ran in 0.008261442184448242 seconds for the subsequent iteration because of the program cache\n"
                    ]
                }
            ],
            "source": [
                "print(f\"Optimized multi-head attention ran in {duration} seconds for the subsequent iteration because of the program cache\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Note that the optimized multi-head attention is 2 orders of magnitude faster than the initial version"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Check that the output of the optimized version matches the output of the original implementation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.from_device                                   in         5178201 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_torch                                      in          332199 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.from_device                                   in         3727969 nanoseconds\n",
                        "\u001b[38;2;000;128;000m                     Op\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Finished Operation ttnn.to_torch                                      in          595607 nanoseconds\n"
                    ]
                }
            ],
            "source": [
                "torch_output = ttnn.to_torch(output)\n",
                "torch_optimized_output = ttnn.to_torch(optimized_output)\n",
                "\n",
                "assert torch.allclose(torch_output, torch_optimized_output)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Close the device"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[38;2;000;128;000m                  Metal\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Closing device 0\n"
                    ]
                }
            ],
            "source": [
                "ttnn.close_device(device)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
